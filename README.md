# nlp_project
HSE Computational Linguistics 4th year final project


## ABTE
Для выделения аспектов мы пользовались натренированной на русском `RuBert`, и дообучали её двумя способами. Первое - полноценный файнтьюн на наших данных. Второе - дообучение последнего слоя через библиотеку [`adapters`](https://docs.adapterhub.ml/model_overview.html). Скелет модели и идею обучения мы взяли [отсюда](https://github.com/nicolezattarin/BERT-Aspect-Based-Sentiment-Analysis/tree/main), и переделали саму модель, чтобы она могла работать с токенизатором, который умеет в спаны, и работала с нашим количеством классов. Внутренности модели лежат в `abte.py`.
Для Берта не подходят спаны, которыми отмечены фрагменты текста в нашем датасете. Берт требует последовательность токенов + такой же длинны последовательность индексов классов.  Функция `clean_data` оформляет данные в датафрейм, `spans_to_ids` - переводит спаны и тексты в последовательности токенов, `predictor` - делает предсказание по тексту и сразу переводит его обратно в спаны и записывает в файл в нужном формате. Все вспомогательные функции ~~и прочие ухищрения~~ лежат в `utils_for_abte.py`
Тетрадка, в которой всё собиралось, училось и тестилось - `nlp_project_abte.ipynb`

[Вот](https://drive.google.com/file/d/10dWiPoGRqGP2bjYbA5FWCqPOp9ek65Jk/view?usp=sharing) сравнительный график обучения двух моделей. NB: лосс на трейне считался через `CrossEntropyLoss` над последовательностями токенов, без перевода в спаны. То есть Берт решал задачу классификации для токенов по одному, а не их последовательностей. Склеивались токены в последовательности уже в пост-обработке на `predictor`, где проверялось, есть ли стыкующиеся токены с одинаковым классом, и все такие объединялись в последовательности.
Вот [здесь](https://drive.google.com/drive/folders/1qlgDgESbVsTUKmwEXEDl62LmSrhOpZf5?usp=sharing) лежат веса и лоссы моделей.


### Задачи
- Тональность по категориям - Поля Карпова
- ABTE - Даша Сидоркина
- ABSA - Катя Козлова
